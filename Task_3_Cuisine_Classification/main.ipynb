{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f77ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification model to predict restaurant cuisine\n",
    "\n",
    "#Step1 - Target and features\n",
    "'''\n",
    "target Column - cuisines\n",
    "Features : All other columns\n",
    "\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#this error occurs always due to kernal restarting means - other file or folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9edb27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Restaurants_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "166dfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#everytime - we need to import the pandas and give the df variable \n",
    "#value of the read_csv and get the csv dataset\n",
    "\n",
    "\n",
    "X = df.drop(\"Cuisines\",axis=1)\n",
    "y = df[\"Cuisines\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2abd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 : train test - split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ce800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b18c08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 : train the classification model( using random forest)\n",
    "X = df.drop(\"Cuisines\", axis=1)\n",
    "y = df[\"Cuisines\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "557475f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a1958ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.<br>Note: This parameter is tree-specific.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D%22sqrt%22\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.accuracy_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=class_weight,-%7B%22balanced%22%2C%20%22balanced_subsample%22%7D%2C%20dict%20or%20list%20of%20dicts%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>The \"balanced_subsample\" mode is the same as \"balanced\" except that<br>weights are computed based on the bootstrap sample for every tree<br>grown.<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the classification model using random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_cls = RandomForestClassifier(random_state=42)\n",
    "model_cls.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions \n",
    "#make predictions\n",
    "\n",
    "y_pred = model_cls.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db44a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18210361067503925"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation \n",
    "#Accuracy score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       0.08      0.20      0.11         5\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         1\n",
      "          40       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          54       0.33      0.33      0.33         3\n",
      "          55       0.00      0.00      0.00         3\n",
      "          56       0.00      0.00      0.00         0\n",
      "          58       0.62      1.00      0.76         8\n",
      "          59       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          78       1.00      1.00      1.00         1\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         2\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         1\n",
      "         148       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         160       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         1\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.02      0.03      0.03        36\n",
      "         178       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         1\n",
      "         183       0.00      0.00      0.00         2\n",
      "         186       0.09      0.06      0.07        32\n",
      "         187       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         9\n",
      "         196       0.00      0.00      0.00         1\n",
      "         200       0.00      0.00      0.00         1\n",
      "         201       0.36      0.19      0.25        21\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         1\n",
      "         204       0.00      0.00      0.00         2\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.00      0.00      0.00         1\n",
      "         211       0.00      0.00      0.00         1\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       0.00      0.00      0.00         1\n",
      "         214       0.00      0.00      0.00         1\n",
      "         217       0.00      0.00      0.00         3\n",
      "         218       0.00      0.00      0.00         2\n",
      "         220       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.40      0.50      0.44        12\n",
      "         233       0.00      0.00      0.00         3\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         1\n",
      "         238       0.00      0.00      0.00         0\n",
      "         239       0.00      0.00      0.00         1\n",
      "         242       0.00      0.00      0.00         1\n",
      "         243       0.14      0.12      0.13         8\n",
      "         246       0.00      0.00      0.00         2\n",
      "         249       0.00      0.00      0.00         3\n",
      "         251       0.00      0.00      0.00         2\n",
      "         252       0.00      0.00      0.00         1\n",
      "         254       0.00      0.00      0.00         1\n",
      "         256       0.00      0.00      0.00         1\n",
      "         257       0.00      0.00      0.00         0\n",
      "         258       0.00      0.00      0.00         1\n",
      "         259       0.00      0.00      0.00         1\n",
      "         260       0.00      0.00      0.00         1\n",
      "         263       0.00      0.00      0.00         0\n",
      "         268       0.00      0.00      0.00         0\n",
      "         269       0.00      0.00      0.00         1\n",
      "         270       0.00      0.00      0.00         1\n",
      "         271       0.00      0.00      0.00         1\n",
      "         272       0.00      0.00      0.00         2\n",
      "         273       0.00      0.00      0.00         1\n",
      "         278       0.00      0.00      0.00         1\n",
      "         282       0.00      0.00      0.00         1\n",
      "         284       0.00      0.00      0.00         0\n",
      "         285       0.00      0.00      0.00         0\n",
      "         286       0.00      0.00      0.00         1\n",
      "         288       0.00      0.00      0.00         1\n",
      "         290       0.00      0.00      0.00         0\n",
      "         291       0.00      0.00      0.00         1\n",
      "         292       0.00      0.00      0.00         1\n",
      "         294       0.00      0.00      0.00         1\n",
      "         297       0.00      0.00      0.00         1\n",
      "         299       0.00      0.00      0.00         1\n",
      "         300       0.00      0.00      0.00         1\n",
      "         304       0.00      0.00      0.00         0\n",
      "         305       0.00      0.00      0.00         0\n",
      "         307       0.33      1.00      0.50         1\n",
      "         308       0.00      0.00      0.00         1\n",
      "         309       0.00      0.00      0.00         0\n",
      "         310       0.25      0.30      0.27        10\n",
      "         311       0.00      0.00      0.00         1\n",
      "         314       0.00      0.00      0.00         1\n",
      "         319       0.00      0.00      0.00         0\n",
      "         320       0.00      0.00      0.00         1\n",
      "         321       0.00      0.00      0.00         0\n",
      "         322       0.00      0.00      0.00         1\n",
      "         327       0.00      0.00      0.00         0\n",
      "         329       0.00      0.00      0.00         2\n",
      "         330       0.00      0.00      0.00         1\n",
      "         331       0.40      0.53      0.46        70\n",
      "         344       0.00      0.00      0.00         3\n",
      "         345       0.00      0.00      0.00         1\n",
      "         346       0.00      0.00      0.00         3\n",
      "         348       0.00      0.00      0.00         1\n",
      "         352       0.00      0.00      0.00         1\n",
      "         355       0.00      0.00      0.00         1\n",
      "         358       0.00      0.00      0.00         1\n",
      "         359       0.00      0.00      0.00         1\n",
      "         360       0.00      0.00      0.00         1\n",
      "         361       0.00      0.00      0.00         2\n",
      "         364       0.00      0.00      0.00         1\n",
      "         370       0.00      0.00      0.00         2\n",
      "         371       0.00      0.00      0.00         1\n",
      "         373       0.00      0.00      0.00         1\n",
      "         376       0.00      0.00      0.00         1\n",
      "         377       0.00      0.00      0.00         1\n",
      "         379       0.00      0.00      0.00         1\n",
      "         380       0.00      0.00      0.00         0\n",
      "         383       0.00      0.00      0.00         1\n",
      "         384       0.00      0.00      0.00         1\n",
      "         388       0.00      0.00      0.00         1\n",
      "         391       0.00      0.00      0.00         0\n",
      "         395       0.00      0.00      0.00         1\n",
      "         397       0.00      0.00      0.00         1\n",
      "         398       0.00      0.00      0.00         1\n",
      "         399       0.00      0.00      0.00         1\n",
      "         400       0.00      0.00      0.00         1\n",
      "         407       0.00      0.00      0.00         1\n",
      "         410       0.00      0.00      0.00         1\n",
      "         412       0.00      0.00      0.00         2\n",
      "         416       0.00      0.00      0.00         1\n",
      "         419       0.00      0.00      0.00         1\n",
      "         420       0.00      0.00      0.00         1\n",
      "         422       0.00      0.00      0.00         1\n",
      "         426       0.00      0.00      0.00         1\n",
      "         433       0.00      0.00      0.00         2\n",
      "         436       0.00      0.00      0.00         0\n",
      "         438       0.00      0.00      0.00         0\n",
      "         441       0.00      0.00      0.00         1\n",
      "         442       0.00      0.00      0.00         1\n",
      "         445       0.00      0.00      0.00         1\n",
      "         447       0.00      0.00      0.00         1\n",
      "         451       0.00      0.00      0.00         1\n",
      "         454       0.00      0.00      0.00         0\n",
      "         455       0.00      0.00      0.00         1\n",
      "         458       0.00      0.00      0.00         0\n",
      "         465       0.00      0.00      0.00         1\n",
      "         468       0.00      0.00      0.00         0\n",
      "         469       0.00      0.00      0.00         0\n",
      "         470       0.00      0.00      0.00         1\n",
      "         472       0.00      0.00      0.00         1\n",
      "         479       0.00      0.00      0.00         1\n",
      "         480       0.00      0.00      0.00         1\n",
      "         484       0.00      0.00      0.00         0\n",
      "         487       0.50      1.00      0.67         3\n",
      "         489       0.00      0.00      0.00         0\n",
      "         492       0.00      0.00      0.00         0\n",
      "         493       0.00      0.00      0.00         0\n",
      "         497       0.14      0.16      0.15        61\n",
      "         498       0.00      0.00      0.00         1\n",
      "         500       0.00      0.00      0.00         1\n",
      "         502       0.00      0.00      0.00         1\n",
      "         503       0.00      0.00      0.00         0\n",
      "         504       0.00      0.00      0.00         1\n",
      "         505       0.00      0.00      0.00         1\n",
      "         509       0.00      0.00      0.00         1\n",
      "         512       0.00      0.00      0.00         2\n",
      "         518       0.07      0.05      0.06        19\n",
      "         521       0.00      0.00      0.00         1\n",
      "         532       0.00      0.00      0.00         0\n",
      "         533       0.00      0.00      0.00         1\n",
      "         536       0.00      0.00      0.00         1\n",
      "         537       0.00      0.00      0.00         1\n",
      "         539       0.00      0.00      0.00         0\n",
      "         545       0.00      0.00      0.00         2\n",
      "         546       0.00      0.00      0.00         4\n",
      "         547       0.00      0.00      0.00         1\n",
      "         549       0.20      0.05      0.07        22\n",
      "         550       0.00      0.00      0.00         0\n",
      "         551       0.00      0.00      0.00         1\n",
      "         552       0.00      0.00      0.00         1\n",
      "         554       0.00      0.00      0.00         1\n",
      "         555       0.00      0.00      0.00         2\n",
      "         556       0.00      0.00      0.00         1\n",
      "         557       0.00      0.00      0.00         0\n",
      "         561       0.00      0.00      0.00         1\n",
      "         563       0.00      0.00      0.00         1\n",
      "         564       0.00      0.00      0.00         2\n",
      "         565       0.00      0.00      0.00         1\n",
      "         566       0.00      0.00      0.00         0\n",
      "         567       0.00      0.00      0.00         1\n",
      "         568       0.00      0.00      0.00         2\n",
      "         575       0.00      0.00      0.00         0\n",
      "         578       0.00      0.00      0.00         1\n",
      "         580       0.00      0.00      0.00         0\n",
      "         581       0.00      0.00      0.00         1\n",
      "         582       0.00      0.00      0.00         2\n",
      "         583       0.00      0.00      0.00         1\n",
      "         585       0.00      0.00      0.00         0\n",
      "         588       0.20      0.09      0.12        11\n",
      "         589       0.50      0.33      0.40         3\n",
      "         591       0.00      0.00      0.00         2\n",
      "         593       0.00      0.00      0.00         1\n",
      "         595       0.00      0.00      0.00         1\n",
      "         597       0.00      0.00      0.00         0\n",
      "         600       0.00      0.00      0.00         0\n",
      "         601       0.00      0.00      0.00         1\n",
      "         602       0.00      0.00      0.00         1\n",
      "         604       0.00      0.00      0.00         2\n",
      "         608       0.00      0.00      0.00         0\n",
      "         610       0.00      0.00      0.00         1\n",
      "         611       0.00      0.00      0.00         1\n",
      "         613       0.00      0.00      0.00         1\n",
      "         614       0.00      0.00      0.00         1\n",
      "         615       0.00      0.00      0.00         1\n",
      "         616       0.00      0.00      0.00         1\n",
      "         623       0.00      0.00      0.00         1\n",
      "         624       0.00      0.00      0.00         1\n",
      "         625       0.00      0.00      0.00         5\n",
      "         626       0.00      0.00      0.00         3\n",
      "         627       0.00      0.00      0.00         1\n",
      "         631       0.00      0.00      0.00         0\n",
      "         632       0.00      0.00      0.00         0\n",
      "         635       0.00      0.00      0.00         0\n",
      "         636       0.00      0.00      0.00         1\n",
      "         641       0.00      0.00      0.00         1\n",
      "         652       0.00      0.00      0.00         1\n",
      "         655       0.00      0.00      0.00         0\n",
      "         658       0.00      0.00      0.00         0\n",
      "         660       0.00      0.00      0.00         3\n",
      "         665       0.00      0.00      0.00         1\n",
      "         666       0.00      0.00      0.00         1\n",
      "         667       0.00      0.00      0.00         0\n",
      "         672       0.00      0.00      0.00         1\n",
      "         674       0.00      0.00      0.00         0\n",
      "         676       0.00      0.00      0.00         1\n",
      "         677       0.00      0.00      0.00         1\n",
      "         678       0.00      0.00      0.00         0\n",
      "         681       0.00      0.00      0.00         0\n",
      "         682       0.00      0.00      0.00         1\n",
      "         684       0.00      0.00      0.00         0\n",
      "         688       0.00      0.00      0.00         0\n",
      "         691       0.00      0.00      0.00         1\n",
      "         693       0.00      0.00      0.00         0\n",
      "         695       0.00      0.00      0.00         0\n",
      "         697       0.00      0.00      0.00         1\n",
      "         709       0.00      0.00      0.00         1\n",
      "         713       0.00      0.00      0.00         1\n",
      "         714       0.00      0.00      0.00         1\n",
      "         719       0.00      0.00      0.00         4\n",
      "         721       0.00      0.00      0.00         1\n",
      "         722       0.00      0.00      0.00         1\n",
      "         725       0.00      0.00      0.00         0\n",
      "         730       0.00      0.00      0.00         1\n",
      "         731       0.00      0.00      0.00         0\n",
      "         732       0.00      0.00      0.00         1\n",
      "         733       0.00      0.00      0.00         1\n",
      "         736       0.00      0.00      0.00         1\n",
      "         737       0.00      0.00      0.00         1\n",
      "         739       0.00      0.00      0.00         1\n",
      "         742       0.00      0.00      0.00         1\n",
      "         747       0.00      0.00      0.00         1\n",
      "         753       0.00      0.00      0.00         1\n",
      "         755       0.00      0.00      0.00         0\n",
      "         758       0.00      0.00      0.00         9\n",
      "         760       0.00      0.00      0.00         3\n",
      "         761       0.00      0.00      0.00         1\n",
      "         764       0.00      0.00      0.00         1\n",
      "         765       0.00      0.00      0.00         6\n",
      "         767       0.00      0.00      0.00         1\n",
      "         770       0.00      0.00      0.00         2\n",
      "         772       0.00      0.00      0.00         1\n",
      "         774       0.00      0.00      0.00         6\n",
      "         775       0.00      0.00      0.00         1\n",
      "         778       0.00      0.00      0.00         1\n",
      "         787       0.00      0.00      0.00         0\n",
      "         788       0.00      0.00      0.00         1\n",
      "         790       0.00      0.00      0.00         1\n",
      "         791       0.00      0.00      0.00         2\n",
      "         793       0.00      0.00      0.00         0\n",
      "         794       0.00      0.00      0.00         0\n",
      "         796       0.00      0.00      0.00         1\n",
      "         802       0.00      0.00      0.00         0\n",
      "         806       0.00      0.00      0.00         0\n",
      "         808       0.00      0.00      0.00         1\n",
      "         809       0.00      0.00      0.00         0\n",
      "         810       0.00      0.00      0.00         3\n",
      "         814       0.00      0.00      0.00         0\n",
      "         817       0.00      0.00      0.00         1\n",
      "         819       0.00      0.00      0.00         1\n",
      "         820       0.00      0.00      0.00         1\n",
      "         821       0.00      0.00      0.00         1\n",
      "         824       0.00      0.00      0.00         0\n",
      "         825       0.00      0.00      0.00         1\n",
      "         826       0.00      0.00      0.00         1\n",
      "         827       0.00      0.00      0.00         1\n",
      "         828       0.17      0.29      0.22        68\n",
      "         831       0.00      0.00      0.00         1\n",
      "         832       0.00      0.00      0.00         1\n",
      "         833       0.00      0.00      0.00         4\n",
      "         834       0.00      0.00      0.00         6\n",
      "         836       0.00      0.00      0.00         0\n",
      "         837       0.70      0.58      0.64        12\n",
      "         840       0.00      0.00      0.00         1\n",
      "         841       0.00      0.00      0.00        10\n",
      "         843       0.00      0.00      0.00         1\n",
      "         845       0.00      0.00      0.00         1\n",
      "         847       0.00      0.00      0.00         1\n",
      "         851       0.00      0.00      0.00         1\n",
      "         854       0.00      0.00      0.00         2\n",
      "         855       0.00      0.00      0.00         0\n",
      "         856       0.00      0.00      0.00         1\n",
      "         859       0.00      0.00      0.00         1\n",
      "         861       0.00      0.00      0.00         1\n",
      "         865       0.00      0.00      0.00         6\n",
      "         868       0.00      0.00      0.00         3\n",
      "         874       0.00      0.00      0.00         2\n",
      "         875       0.00      0.00      0.00         1\n",
      "         878       0.00      0.00      0.00         3\n",
      "         879       0.00      0.00      0.00         1\n",
      "         880       0.00      0.00      0.00         1\n",
      "         882       0.00      0.00      0.00         1\n",
      "         883       0.00      0.00      0.00         1\n",
      "         886       0.00      0.00      0.00         5\n",
      "         887       0.00      0.00      0.00         1\n",
      "         888       0.00      0.00      0.00         1\n",
      "         889       0.00      0.00      0.00         0\n",
      "         892       0.25      1.00      0.40         1\n",
      "         894       0.00      0.00      0.00         2\n",
      "         895       0.18      0.31      0.23        13\n",
      "         897       0.00      0.00      0.00         2\n",
      "         898       0.00      0.00      0.00         1\n",
      "         899       0.00      0.00      0.00         1\n",
      "         905       0.00      0.00      0.00         1\n",
      "         906       0.00      0.00      0.00         0\n",
      "         909       0.00      0.00      0.00         2\n",
      "         913       0.00      0.00      0.00         2\n",
      "         914       0.00      0.00      0.00         1\n",
      "         916       1.00      0.50      0.67         2\n",
      "         919       0.00      0.00      0.00         1\n",
      "         920       0.00      0.00      0.00         1\n",
      "         921       0.00      0.00      0.00         1\n",
      "         926       0.00      0.00      0.00         1\n",
      "         928       0.00      0.00      0.00         1\n",
      "         931       0.00      0.00      0.00         1\n",
      "         932       0.00      0.00      0.00         1\n",
      "         933       0.00      0.00      0.00         1\n",
      "         934       0.00      0.00      0.00         1\n",
      "         940       0.00      0.00      0.00         1\n",
      "         941       0.00      0.00      0.00         1\n",
      "         944       0.00      0.00      0.00         0\n",
      "         945       0.00      0.00      0.00         1\n",
      "         947       0.00      0.00      0.00         1\n",
      "         951       0.00      0.00      0.00         4\n",
      "         953       0.00      0.00      0.00         1\n",
      "         955       0.00      0.00      0.00         1\n",
      "         960       0.00      0.00      0.00         1\n",
      "         964       0.00      0.00      0.00         1\n",
      "         967       0.00      0.00      0.00         1\n",
      "         969       0.00      0.00      0.00         0\n",
      "         972       0.50      1.00      0.67         1\n",
      "         975       0.00      0.00      0.00         1\n",
      "         978       0.00      0.00      0.00         1\n",
      "         980       0.00      0.00      0.00         1\n",
      "         981       0.00      0.00      0.00         0\n",
      "         982       0.62      0.36      0.45        14\n",
      "         984       0.00      0.00      0.00         1\n",
      "         985       0.00      0.00      0.00         1\n",
      "         986       0.36      0.29      0.32        14\n",
      "         987       0.00      0.00      0.00         0\n",
      "         993       0.00      0.00      0.00         1\n",
      "         995       0.00      0.00      0.00         4\n",
      "         996       0.00      0.00      0.00         0\n",
      "        1002       0.00      0.00      0.00         0\n",
      "        1004       0.00      0.00      0.00         0\n",
      "        1005       0.00      0.00      0.00         1\n",
      "        1007       0.00      0.00      0.00         0\n",
      "        1010       0.00      0.00      0.00         1\n",
      "        1012       0.00      0.00      0.00         1\n",
      "        1017       0.00      0.00      0.00         0\n",
      "        1018       0.00      0.00      0.00         1\n",
      "        1019       0.00      0.00      0.00         0\n",
      "        1020       0.00      0.00      0.00         1\n",
      "        1022       0.00      0.00      0.00         2\n",
      "        1024       0.00      0.00      0.00         0\n",
      "        1030       0.00      0.00      0.00         1\n",
      "        1031       0.00      0.00      0.00        19\n",
      "        1039       0.00      0.00      0.00         1\n",
      "        1040       0.00      0.00      0.00         1\n",
      "        1044       0.00      0.00      0.00         1\n",
      "        1046       0.00      0.00      0.00         0\n",
      "        1047       0.00      0.00      0.00         0\n",
      "        1048       0.00      0.00      0.00         0\n",
      "        1050       1.00      0.50      0.67         2\n",
      "        1051       0.00      0.00      0.00         1\n",
      "        1057       0.00      0.00      0.00         1\n",
      "        1059       0.00      0.00      0.00         1\n",
      "        1060       0.00      0.00      0.00         0\n",
      "        1061       0.00      0.00      0.00         1\n",
      "        1063       0.00      0.00      0.00         1\n",
      "        1064       0.00      0.00      0.00         1\n",
      "        1065       0.00      0.00      0.00         5\n",
      "        1068       0.00      0.00      0.00         1\n",
      "        1071       0.00      0.00      0.00         1\n",
      "        1072       0.00      0.00      0.00         1\n",
      "        1075       0.00      0.00      0.00         1\n",
      "        1077       0.00      0.00      0.00         1\n",
      "        1078       0.00      0.00      0.00         1\n",
      "        1079       0.00      0.00      0.00         2\n",
      "        1080       0.00      0.00      0.00         0\n",
      "        1081       0.00      0.00      0.00         1\n",
      "        1084       0.00      0.00      0.00         1\n",
      "        1094       0.00      0.00      0.00         1\n",
      "        1095       0.00      0.00      0.00         0\n",
      "        1098       0.00      0.00      0.00         2\n",
      "        1099       0.00      0.00      0.00         0\n",
      "        1102       0.75      0.75      0.75         8\n",
      "        1104       0.00      0.00      0.00         0\n",
      "        1111       0.00      0.00      0.00         5\n",
      "        1112       0.00      0.00      0.00         0\n",
      "        1113       0.00      0.00      0.00         0\n",
      "        1114       0.00      0.00      0.00         0\n",
      "        1115       0.00      0.00      0.00         1\n",
      "        1116       0.00      0.00      0.00         2\n",
      "        1119       0.00      0.00      0.00         1\n",
      "        1120       0.00      0.00      0.00         0\n",
      "        1122       0.00      0.00      0.00         2\n",
      "        1125       0.00      0.00      0.00         0\n",
      "        1126       0.25      0.20      0.22         5\n",
      "        1128       0.00      0.00      0.00         1\n",
      "        1132       0.00      0.00      0.00         1\n",
      "        1134       0.00      0.00      0.00         0\n",
      "        1135       0.00      0.00      0.00         2\n",
      "        1138       0.00      0.00      0.00         1\n",
      "        1140       0.00      0.00      0.00         1\n",
      "        1141       0.00      0.00      0.00         1\n",
      "        1142       0.00      0.00      0.00         0\n",
      "        1143       0.00      0.00      0.00         0\n",
      "        1144       0.00      0.00      0.00         1\n",
      "        1147       0.00      0.00      0.00         1\n",
      "        1148       0.00      0.00      0.00         0\n",
      "        1153       0.00      0.00      0.00         1\n",
      "        1156       0.00      0.00      0.00         0\n",
      "        1157       0.00      0.00      0.00         1\n",
      "        1159       0.00      0.00      0.00         1\n",
      "        1161       0.00      0.00      0.00         1\n",
      "        1165       0.00      0.00      0.00         1\n",
      "        1166       0.00      0.00      0.00         0\n",
      "        1168       0.00      0.00      0.00         0\n",
      "        1170       0.00      0.00      0.00         3\n",
      "        1171       0.00      0.00      0.00         0\n",
      "        1172       0.00      0.00      0.00         0\n",
      "        1178       0.00      0.00      0.00         2\n",
      "        1180       0.00      0.00      0.00         1\n",
      "        1182       0.00      0.00      0.00         1\n",
      "        1184       0.00      0.00      0.00         1\n",
      "        1185       0.00      0.00      0.00         0\n",
      "        1186       0.00      0.00      0.00         1\n",
      "        1187       0.00      0.00      0.00         1\n",
      "        1190       0.00      0.00      0.00         1\n",
      "        1192       0.00      0.00      0.00         1\n",
      "        1193       0.00      0.00      0.00         0\n",
      "        1196       0.00      0.00      0.00         1\n",
      "        1198       0.00      0.00      0.00         1\n",
      "        1204       0.00      0.00      0.00         1\n",
      "        1205       0.00      0.00      0.00         0\n",
      "        1207       0.00      0.00      0.00         1\n",
      "        1208       0.00      0.00      0.00         1\n",
      "        1210       0.00      0.00      0.00         0\n",
      "        1212       0.18      0.33      0.24         6\n",
      "        1213       0.00      0.00      0.00         1\n",
      "        1215       0.00      0.00      0.00         1\n",
      "        1217       0.00      0.00      0.00         3\n",
      "        1218       0.00      0.00      0.00         0\n",
      "        1223       0.00      0.00      0.00         0\n",
      "        1224       0.00      0.00      0.00         1\n",
      "        1225       0.00      0.00      0.00         1\n",
      "        1228       0.00      0.00      0.00         1\n",
      "        1231       0.00      0.00      0.00         1\n",
      "        1233       0.00      0.00      0.00         0\n",
      "        1234       0.00      0.00      0.00         1\n",
      "        1235       0.08      0.08      0.08        13\n",
      "        1237       0.00      0.00      0.00         1\n",
      "        1238       0.00      0.00      0.00         0\n",
      "        1241       0.00      0.00      0.00         0\n",
      "        1243       0.00      0.00      0.00         1\n",
      "        1250       0.00      0.00      0.00         1\n",
      "        1252       0.00      0.00      0.00         0\n",
      "        1254       0.00      0.00      0.00         1\n",
      "        1259       0.00      0.00      0.00         1\n",
      "        1261       0.00      0.00      0.00         1\n",
      "        1262       0.22      0.33      0.27        18\n",
      "        1264       0.00      0.00      0.00         2\n",
      "        1265       0.00      0.00      0.00         1\n",
      "        1272       0.00      0.00      0.00         2\n",
      "        1275       0.06      0.05      0.05        22\n",
      "        1277       0.00      0.00      0.00         4\n",
      "        1278       0.00      0.00      0.00         1\n",
      "        1281       0.00      0.00      0.00         0\n",
      "        1284       0.00      0.00      0.00         1\n",
      "        1286       0.00      0.00      0.00         0\n",
      "        1287       0.00      0.00      0.00         1\n",
      "        1288       0.00      0.00      0.00        14\n",
      "        1290       0.00      0.00      0.00         3\n",
      "        1291       0.00      0.00      0.00         0\n",
      "        1292       0.00      0.00      0.00         1\n",
      "        1294       0.00      0.00      0.00         0\n",
      "        1296       0.00      0.00      0.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1304       0.00      0.00      0.00         1\n",
      "        1306       0.25      0.56      0.34       202\n",
      "        1311       0.00      0.00      0.00         1\n",
      "        1314       0.00      0.00      0.00         0\n",
      "        1315       0.00      0.00      0.00         0\n",
      "        1320       0.00      0.00      0.00         1\n",
      "        1321       0.00      0.00      0.00         4\n",
      "        1323       1.00      1.00      1.00         2\n",
      "        1329       0.15      0.29      0.20       102\n",
      "        1333       0.00      0.00      0.00         2\n",
      "        1334       0.12      0.17      0.14        12\n",
      "        1336       0.00      0.00      0.00         1\n",
      "        1338       0.00      0.00      0.00         1\n",
      "        1340       0.00      0.00      0.00         1\n",
      "        1341       0.00      0.00      0.00         1\n",
      "        1343       0.00      0.00      0.00         1\n",
      "        1345       0.00      0.00      0.00         1\n",
      "        1348       0.33      0.07      0.11        15\n",
      "        1349       0.00      0.00      0.00         0\n",
      "        1352       0.00      0.00      0.00         1\n",
      "        1353       0.00      0.00      0.00         0\n",
      "        1354       0.00      0.00      0.00         1\n",
      "        1355       0.00      0.00      0.00         3\n",
      "        1356       0.00      0.00      0.00         0\n",
      "        1357       0.00      0.00      0.00         0\n",
      "        1361       0.00      0.00      0.00         1\n",
      "        1362       0.00      0.00      0.00         1\n",
      "        1371       0.00      0.00      0.00         0\n",
      "        1373       0.00      0.00      0.00        17\n",
      "        1375       0.00      0.00      0.00         1\n",
      "        1376       0.00      0.00      0.00         1\n",
      "        1378       0.00      0.00      0.00         1\n",
      "        1381       0.00      0.00      0.00        11\n",
      "        1383       0.00      0.00      0.00         1\n",
      "        1384       0.00      0.00      0.00         3\n",
      "        1386       0.00      0.00      0.00         2\n",
      "        1392       0.00      0.00      0.00         1\n",
      "        1394       0.00      0.00      0.00         0\n",
      "        1401       0.00      0.00      0.00         5\n",
      "        1403       0.00      0.00      0.00         1\n",
      "        1404       0.00      0.00      0.00         1\n",
      "        1406       0.00      0.00      0.00         3\n",
      "        1408       0.00      0.00      0.00         0\n",
      "        1409       0.00      0.00      0.00         1\n",
      "        1412       0.00      0.00      0.00         0\n",
      "        1414       0.00      0.00      0.00         1\n",
      "        1419       0.00      0.00      0.00         1\n",
      "        1420       0.00      0.00      0.00         0\n",
      "        1421       0.00      0.00      0.00         0\n",
      "        1422       0.00      0.00      0.00         3\n",
      "        1427       0.00      0.00      0.00         1\n",
      "        1428       0.00      0.00      0.00         1\n",
      "        1430       0.00      0.00      0.00         1\n",
      "        1435       0.00      0.00      0.00         1\n",
      "        1437       0.00      0.00      0.00         0\n",
      "        1439       0.00      0.00      0.00         1\n",
      "        1441       0.00      0.00      0.00         1\n",
      "        1443       0.00      0.00      0.00         1\n",
      "        1444       0.25      0.07      0.11        14\n",
      "        1446       0.00      0.00      0.00         1\n",
      "        1448       0.00      0.00      0.00         4\n",
      "        1458       0.00      0.00      0.00         1\n",
      "        1459       0.00      0.00      0.00         0\n",
      "        1464       0.00      0.00      0.00         1\n",
      "        1465       0.00      0.00      0.00         1\n",
      "        1466       0.00      0.00      0.00         0\n",
      "        1468       0.00      0.00      0.00         1\n",
      "        1469       0.00      0.00      0.00         1\n",
      "        1472       0.00      0.00      0.00         1\n",
      "        1475       0.00      0.00      0.00         1\n",
      "        1476       0.00      0.00      0.00         1\n",
      "        1477       0.00      0.00      0.00         1\n",
      "        1478       0.00      0.00      0.00         1\n",
      "        1479       0.00      0.00      0.00         1\n",
      "        1483       0.00      0.00      0.00         0\n",
      "        1484       0.00      0.00      0.00         1\n",
      "        1491       0.00      0.00      0.00         1\n",
      "        1496       0.00      0.00      0.00         2\n",
      "        1497       0.00      0.00      0.00         0\n",
      "        1499       0.00      0.00      0.00         0\n",
      "        1503       0.00      0.00      0.00         1\n",
      "        1506       0.00      0.00      0.00         1\n",
      "        1508       0.00      0.00      0.00         2\n",
      "        1510       0.00      0.00      0.00         1\n",
      "        1512       0.00      0.00      0.00         1\n",
      "        1514       0.09      0.24      0.13        46\n",
      "        1516       0.00      0.00      0.00         1\n",
      "        1518       0.00      0.00      0.00         2\n",
      "        1519       0.00      0.00      0.00         1\n",
      "        1520       0.14      0.14      0.14        37\n",
      "        1521       0.00      0.00      0.00         1\n",
      "        1524       0.00      0.00      0.00         1\n",
      "        1525       0.00      0.00      0.00         1\n",
      "        1526       0.00      0.00      0.00         0\n",
      "        1527       0.00      0.00      0.00         0\n",
      "        1528       0.00      0.00      0.00         1\n",
      "        1529       0.00      0.00      0.00         0\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1532       0.00      0.00      0.00         0\n",
      "        1533       0.00      0.00      0.00         1\n",
      "        1547       0.00      0.00      0.00         1\n",
      "        1549       0.00      0.00      0.00         0\n",
      "        1550       0.00      0.00      0.00         1\n",
      "        1551       0.00      0.00      0.00         1\n",
      "        1553       0.00      0.00      0.00         1\n",
      "        1554       0.00      0.00      0.00         7\n",
      "        1557       0.00      0.00      0.00         1\n",
      "        1559       0.00      0.00      0.00         9\n",
      "        1560       0.00      0.00      0.00         7\n",
      "        1568       0.00      0.00      0.00         1\n",
      "        1569       0.00      0.00      0.00         1\n",
      "        1570       1.00      0.50      0.67         2\n",
      "        1571       0.00      0.00      0.00         2\n",
      "        1573       0.00      0.00      0.00         3\n",
      "        1574       0.00      0.00      0.00         1\n",
      "        1578       0.00      0.00      0.00         1\n",
      "        1579       0.00      0.00      0.00         1\n",
      "        1585       1.00      1.00      1.00         1\n",
      "        1587       0.00      0.00      0.00         1\n",
      "        1588       0.00      0.00      0.00         1\n",
      "        1590       0.00      0.00      0.00         5\n",
      "        1592       0.00      0.00      0.00         1\n",
      "        1594       0.00      0.00      0.00         1\n",
      "        1604       0.00      0.00      0.00         1\n",
      "        1606       0.00      0.00      0.00         1\n",
      "        1607       0.00      0.00      0.00         0\n",
      "        1608       0.00      0.00      0.00         1\n",
      "        1609       0.00      0.00      0.00         0\n",
      "        1610       0.00      0.00      0.00         1\n",
      "        1617       0.00      0.00      0.00         1\n",
      "        1618       0.00      0.00      0.00         9\n",
      "        1619       0.00      0.00      0.00         1\n",
      "        1620       0.00      0.00      0.00         0\n",
      "        1621       0.00      0.00      0.00         1\n",
      "        1622       0.50      1.00      0.67         1\n",
      "        1626       0.76      0.55      0.64        29\n",
      "        1627       0.00      0.00      0.00         1\n",
      "        1631       0.00      0.00      0.00         4\n",
      "        1633       0.00      0.00      0.00         1\n",
      "        1636       0.00      0.00      0.00         1\n",
      "        1637       0.00      0.00      0.00         1\n",
      "        1640       0.00      0.00      0.00         1\n",
      "        1645       0.00      0.00      0.00         2\n",
      "        1650       0.00      0.00      0.00         8\n",
      "        1651       0.00      0.00      0.00         2\n",
      "        1652       0.00      0.00      0.00         1\n",
      "        1653       0.00      0.00      0.00         1\n",
      "        1655       0.83      0.62      0.71         8\n",
      "        1656       0.00      0.00      0.00         1\n",
      "        1657       0.00      0.00      0.00         1\n",
      "        1663       0.00      0.00      0.00         1\n",
      "        1664       0.00      0.00      0.00         0\n",
      "        1666       0.00      0.00      0.00         0\n",
      "        1667       0.00      0.00      0.00         1\n",
      "        1669       0.00      0.00      0.00         0\n",
      "        1680       0.00      0.00      0.00         1\n",
      "        1682       0.00      0.00      0.00         1\n",
      "        1683       0.00      0.00      0.00         1\n",
      "        1688       0.00      0.00      0.00         0\n",
      "        1693       0.00      0.00      0.00         1\n",
      "        1694       0.00      0.00      0.00         1\n",
      "        1695       1.00      1.00      1.00         1\n",
      "        1696       0.00      0.00      0.00         0\n",
      "        1698       0.00      0.00      0.00         1\n",
      "        1699       0.10      0.05      0.06        22\n",
      "        1701       0.00      0.00      0.00         1\n",
      "        1705       0.00      0.00      0.00         6\n",
      "        1708       0.00      0.00      0.00         1\n",
      "        1709       0.00      0.00      0.00         1\n",
      "        1710       0.00      0.00      0.00         1\n",
      "        1712       0.00      0.00      0.00         1\n",
      "        1716       0.00      0.00      0.00         1\n",
      "        1718       0.00      0.00      0.00         1\n",
      "        1720       0.00      0.00      0.00         1\n",
      "        1722       0.00      0.00      0.00         5\n",
      "        1723       0.29      0.20      0.24        10\n",
      "        1724       0.00      0.00      0.00         1\n",
      "        1725       0.00      0.00      0.00         2\n",
      "        1727       0.00      0.00      0.00         1\n",
      "        1730       0.00      0.00      0.00         1\n",
      "        1731       0.00      0.00      0.00         1\n",
      "        1732       0.00      0.00      0.00         1\n",
      "        1736       0.00      0.00      0.00         1\n",
      "        1741       0.00      0.00      0.00         1\n",
      "        1743       0.00      0.00      0.00         1\n",
      "        1744       0.00      0.00      0.00         1\n",
      "        1746       0.00      0.00      0.00         1\n",
      "        1749       0.26      0.27      0.26        33\n",
      "        1750       0.00      0.00      0.00         2\n",
      "        1751       0.00      0.00      0.00         2\n",
      "        1752       0.00      0.00      0.00         0\n",
      "        1754       0.00      0.00      0.00         1\n",
      "        1756       0.00      0.00      0.00         0\n",
      "        1757       0.00      0.00      0.00         1\n",
      "        1758       0.00      0.00      0.00         1\n",
      "        1760       0.00      0.00      0.00         2\n",
      "        1761       0.00      0.00      0.00         2\n",
      "        1765       0.00      0.00      0.00         4\n",
      "        1766       0.00      0.00      0.00         1\n",
      "        1769       0.00      0.00      0.00         2\n",
      "        1771       0.00      0.00      0.00         2\n",
      "        1775       0.00      0.00      0.00         2\n",
      "        1778       0.00      0.00      0.00         2\n",
      "        1779       1.00      1.00      1.00         1\n",
      "        1780       0.00      0.00      0.00         1\n",
      "        1781       0.00      0.00      0.00         0\n",
      "        1782       0.00      0.00      0.00         0\n",
      "        1784       0.00      0.00      0.00         0\n",
      "        1785       0.00      0.00      0.00         0\n",
      "        1787       0.00      0.00      0.00         1\n",
      "        1788       0.00      0.00      0.00         0\n",
      "        1792       0.00      0.00      0.00         2\n",
      "        1793       0.00      0.00      0.00         1\n",
      "        1795       0.00      0.00      0.00         0\n",
      "        1799       0.00      0.00      0.00         1\n",
      "        1807       0.00      0.00      0.00         3\n",
      "        1809       0.00      0.00      0.00         1\n",
      "        1815       0.00      0.00      0.00         1\n",
      "        1823       0.00      0.00      0.00         1\n",
      "        1825       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.18      1911\n",
      "   macro avg       0.03      0.03      0.03      1911\n",
      "weighted avg       0.14      0.18      0.15      1911\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#Detailed report \n",
    "print(classification_report(y_test, y_pred))\n",
    "#Accuracy prints a number between 0 and 1\n",
    "\n",
    "#Report shows precision, recall, f1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bf18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
